{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38e5d2d-7587-4192-90f2-b58e6c62f08c",
   "metadata": {},
   "source": [
    "# Self Discover\n",
    "\n",
    "An implementation of the [Self-Discover paper](https://arxiv.org/pdf/2402.03620.pdf).\n",
    "\n",
    "Based on [this implementation from @catid](https://github.com/catid/self-discover/tree/main?tab=readme-ov-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18d8f24-5d9a-45c5-9739-6f3c4ed6c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_openai\n",
    "from langchain import Hub, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f554045-6e79-42d3-be4b-835bbbd0b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = langchain_openai.ChatOpenAI(temperature=0, model=\"gpt-4-turbo-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9925aa-638a-4862-823e-9803402b8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_prompt = Hub.pull(\"hwchase17/self-discovery-select\")\n",
    "adapt_prompt = Hub.pull(\"hwchase17/self-discovery-adapt\")\n",
    "structured_prompt = Hub.pull(\"hwchase17/self-discovery-structure\")\n",
    "reasoning_prompt = Hub.pull(\"hwchase17/self-discovery-reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cc5c8c-f6a5-42c7-9ed5-780d79b3b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select several reasoning modules that are crucial to utilize in order to solve the given task:\n",
      "\n",
      "All reasoning module descriptions:\n",
      "\u001b[33;1m\u001b[1;3m{reasoning_modules}\u001b[0m\n",
      "\n",
      "Task: \u001b[33;1m\u001b[1;3m{task_description}\u001b[0m\n",
      "\n",
      "Select several modules are crucial for solving the task above:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(select_prompt.format(reasoning_modules=reasoning_modules_str, task_description=task_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26eaa6bc-5202-4b22-9522-33f227c8eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rephrase and specify each reasoning module so that it better helps solving the task:\n",
      "\n",
      "SELECTED module descriptions:\n",
      "\u001b[33;1m\u001b[1;3m{selected_modules}\u001b[0m\n",
      "\n",
      "Task: \u001b[33;1m\u001b[1;3m{task_description}\u001b[0m\n",
      "\n",
      "Adapt each reasoning module description to better solve the task:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(adapt_prompt.format(selected_modules=selected_modules_str, task_description=task_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93253a9-8f50-49dd-8815-c3927bae1905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operationalize the reasoning modules into a step-by-step reasoning plan in JSON format:\n",
      "\n",
      "Here's an example:\n",
      "\n",
      "Example task:\n",
      "\n",
      "If you follow these instructions, do you return to the starting point? Always face forward. Take 1 step backward. Take 9 steps left. Take 2 steps backward. Take 6 steps forward. Take 4 steps forward. Take 4 steps backward. Take 3 steps right.\n",
      "\n",
      "Example reasoning structure:\n",
      "\n",
      "{\n",
      "    \"Position after instruction 1\":\n",
      "    \"Position after instruction 2\":\n",
      "    \"Position after instruction n\":\n",
      "    \"Is final position the same as starting position\":\n",
      "}\n",
      "\n",
      "Adapted module description:\n",
      "\u001b[33;1m\u001b[1;3m{adapted_modules}\u001b[0m\n",
      "\n",
      "Task: \u001b[33;1m\u001b[1;3m{task_description}\u001b[0m\n",
      "\n",
      "Implement a reasoning structure for solvers to follow step-by-step and arrive at correct answer.\n",
      "\n",
      "Note: do NOT actually arrive at a conclusion in this pass. Your job is to generate a PLAN so that in the future you can fill it out and arrive at the correct conclusion for tasks like this\n"
     ]
    }
   ],
   "source": [
    "print(structured_prompt.format(adapted_modules=adapted_modules_str, task_description=task_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9af01d-da28-4785-b069-efea61905cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['reasoning_structure', 'task_description'], template='Follow the step-by-step reasoning plan in JSON to correctly solve the task. Fill in the values following the keys by reasoning specifically about the task given. Do not simply rephrase the keys.\\n    \\nReasoning Structure:\\n{reasoning_structure}\\n\\nTask: {task_description}')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reasoning_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399bf160-e257-429f-b27e-66d4063f195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_modules_str = '\\n'.join(reasoning_modules)\n",
    "selected_modules = model.generate_text(prompt=select_prompt, stop_sequences=['Task:'])\n",
    "selected_modules_str = selected_modules.strip()[len(task_example)+6:]\n",
    "\n",
    "adapted_modules_str = '\\n'.join(selected_modules.strip().split('\\n')[1:])\n",
    "adapted_modules = model.generate_text(prompt=adapt_prompt, stop_sequences=['Task:'])\n",
    "adapted_modules_str = adapted_modules.strip()[len(task_example)+6:]\n",
    "\n",
    "structured_prompt_str = model.generate_text(prompt=structured_prompt, stop_sequences=['Task:'])\n",
    "adapted_modules_str = structured_prompt_str.strip()[len(task_example)+6:]\n",
    "\n",
    "reasoning_structure = model.generate_text(prompt=reasoning_prompt, stop_sequences=['Task:'])\n",
    "reasoning_structure = reasoning_structure.strip()['{':-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fe385b-cf5d-4581-80e7-55462f5628bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_chain = RunnablePassthrough.assign(selected_modules=selected_modules)\n",
    "                   .assign(adapted_modules=adapted_modules)\n",
    "                   .assign(reasoning_structure=reasoning_structure)\n",
    "                   .assign(answer=reasoning_structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cbfbe81-f751-42da-843a-f9003ace663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided reasoning structure and the SVG path element given, letâ€™s analyze the path commands to identify the shape.\\n\\n**Step 1: Detailed Path Analysis**\\n- Description: The SVG path provided contains multiple 'M' (moveto) and 'L' (lineto) commands. Each command specifies a point in a 2D coordinate system.\\n- Action: The path commands are as follows:\\n  1. M 55.57,80.69 (Move to point)\\n  2. L 57.38,65.80 (Line to point)\\n  3. M 57.38,65.80 (Move to point)\\n  4. L 48.90,57.46 (Line to point)\\n  5. M 48.90,57.46 (Move to point)\\n  6. L 45.58,47.78 (Line to point)\\n  7. M 45.58,47.78 (Move to point)\\n  8. L 53.25,36.07 (Line to point)\\n  9. L 66.29,48.90 (Line to point)\\n  10. L 78.69,61.09 (Line to point)\\n  11. L 55.57,80.69 (Line to point)\\n- Expected Outcome: A clear understanding of the sequence and direction of each path command.\\n\\n**Step 2: Path Command Interpretation**\\n- Description: The 'M' and 'L' commands are used to move the 'pen' to a starting point and draw lines to subsequent points, respectively.\\n- Action: The commands describe a shape starting at (55.57,80.69), drawing lines through several points, and finally closing the shape by returning to the starting point.\\n- Expected Outcome: A segmented representation showing vertices and edges.\\n\\n**Step 3: Shape Visualization**\\n- Description: Mentally construct the shape from the provided path commands.\\n- Action: Visualize the lines connecting in sequence from the starting point, through each point described by the 'L' commands, and back to the starting point.\\n- Expected Outcome: A mental image of the potential shape, considering the sequence and direction of path commands.\\n\\n**Step 4: Path-to-Shape Synthesis**\\n- Description: Understand the SVG path as a component within the broader context of vector graphics, focusing on how individual path commands interlink to form a cohesive shape.\\n- Action: Analyze the systemic relationship between the starting and ending points of segments and their collective role in shaping the final figure.\\n- Expected Outcome: Identification of the overall shape based on the cumulative effect of each command.\\n\\n**Step 5: Sequential Command Analysis**\\n- Description: Analyze each 'M' to 'L' sequence in isolation.\\n- Action: Break down the path into individual commands and analyze each separately before synthesizing the findings.\\n- Expected Outcome: A clearer understanding of the shape being drawn, segment by segment.\\n\\n**Step 6: Command-to-Geometry Mapping**\\n- Description: Map the abstract 'M' and 'L' commands onto a concrete geometric representation.\\n- Action: Construct a mental image of the shape as each command is processed.\\n- Expected Outcome: A dynamic visualization that evolves with each new piece of path data.\\n\\n**Conclusion**\\n- Description: Determine the shape drawn by the SVG path element.\\n- Action: Review the outcomes of each analysis step and synthesize the information to identify the shape.\\n- Expected Outcome: The correct identification of the shape, supported by the structured analysis and reasoning process.\\n"
     ]
    }
   ],
   "source": [
    "print(run_chain.invoke(task_description=task_example).answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f8b67b",
   "metadata": {},
   "source": [
    "# AutoGPT with LangChain primitives\n",
    "\n",
    "Implementation of https://github.com/Significant-Gravitas/Auto-GPT but with LangChain primitives (LLMs, PromptTemplates, VectorStores, Embeddings, Tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192496a7",
   "metadata": {},
   "source": [
    "## Set up tools\n",
    "\n",
    "We'll set up an AutoGPT with a search tool, a write-file tool, and a read-file tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2c9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.agents import Tool\n",
    "from langchain_community.tools.file_management.read import ReadFileTool\n",
    "from langchain_community.tools.file_management.write import WriteFileTool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "try:\n",
    "    search = SerpAPIWrapper()\n",
    "    tools: List[Tool] = [\n",
    "        Tool(\n",
    "            name=\"search\",\n",
    "            func=search.run,\n",
    "            description=\"useful for when you need to answer questions about current events. You should ask targeted questions\",\n",
    "        ),\n",
    "        WriteFileTool(),\n",
    "        ReadFileTool(),\n",
    "    ]\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SerpAPIWrapper: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39ee28",
   "metadata": {},
   "source": [
    "## Set up memory\n",
    "\n",
    "The memory here is used for the agent's intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72bc204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df7b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your embedding model\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "# Initialize the vectorstore as empty\n",
    "import faiss\n",
    "\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fd657",
   "metadata": {},
   "source": [
    "## Setup model and AutoGPT\n",
    "\n",
    "Initialize everything! We will use ChatOpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3393bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.autonomous_agents

# Exploring OpenAI V1 functionality

# On 11.06.23 OpenAI released a number of new features, and along with it bumped their Python SDK to 1.0.0.
# This notebook shows off the new features and how to use them with LangChain.

# Needed packages
!pip install -U openai langchain langchain-experimental

# Importing necessary modules
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

# Exploring Vision features
print("\n## Vision\n")
print(
    "OpenAI released multi-modal models, which can take a sequence of text and images as input.\n"
)

chat = ChatOpenAI(
    model="gpt-4-vision-preview", max_tokens=256
)

response = chat.invoke(
    [
        HumanMessage(
            content=[
                {
                    "type": "text",
                    "text": "What is this image showing",
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/langchain_stack.png",
                        "detail": "auto",
                    },
                },
            ]
        )
    ]
)

print(response.content)

# Exploring OpenAI Assistants
print("\n## OpenAI assistants\n")
print(
    "The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling\n"
)

# Using only OpenAI tools
from langchain.agents.openai_assistant import OpenAIAssistantRunnable

interpreter_assistant = OpenAIAssistantRunnable.create_assistant(
    name="langchain assistant",
    instructions="You are a personal math tutor. Write and run code to answer math questions.",
    tools=[{"type": "code_interpreter"}],
    model="gpt-4-1106-preview",
)

output = interpreter_assistant.invoke({"content": "What's 10 - 4 raised to the 2.7"})
print(output.content)

# As a LangChain agent with arbitrary tools
!pip install e2b duckduckgo-search

from langchain.tools import DuckDuckGoSearchRun, E2BDataAnalysisTool

tools = [E2BDataAnalysisTool(api_key="..."), DuckDuckGoSearchRun()]

agent = OpenAIAssistantRunnable.create_assistant(
    name="langchain assistant e2b tool",
    instructions="You are a personal math tutor. Write and run code to answer math questions. You can also search the internet.",
    tools=tools,
    model="gpt-4-1106-preview",
    as_agent=True,
)

# Using AgentExecutor
from langchain.agents import AgentExecutor

agent_executor = AgentExecutor(agent=agent, tools=tools)
response = agent_executor.invoke({"content": "What's the weather in SF today divided by 2.7"})
print(response.content)

# Custom execution
def execute_agent(agent, tools, input):
    tool_map = {tool.name: tool for tool in tools}
    response = agent.invoke(input)
    while not isinstance(response, AgentFinish):
        tool_outputs = []
        for action in response:
            tool_output = tool_map[action.tool].invoke(action.tool_input)
            print(action.tool, action.tool_input, tool_output, end="\n\n")
            tool_outputs.append(
                {
                    "output": tool_output,
                    "tool_call_id": action.tool_call_id,
                }
            )
        response = agent.invoke(
            {
                "tool_outputs": tool_outputs,
                "run_id": action.run_id,
                "thread_id": action.thread_id,
            }
        )

    return response

response = execute_agent(agent, tools, {"content": "What's 10 - 4 raised to the 2.7"})
print(response.return_values["output"])

# JSON mode
chat = ChatOpenAI(
    model="gpt-3.5-turbo-1106"
).bind(response_format={"type": "json_object"})

output = chat.generate(
    [
        [
            SystemMessage(
                content="Extract the 'name' and 'origin' of any companies mentioned in the following statement. Return a JSON list."
            ),
            HumanMessage(
                content="Google was founded in the USA, while Deepmind was founded in the UK"
            ),
        ]
    ]
)

print(output.llm_output)

# System fingerprint
chat = ChatOpenAI(model="gpt-3.5-turbo-1106")
output = chat.generate(
    [
        [
            SystemMessage(
                content="Extract the 'name' and 'origin' of any companies mentioned in the following statement. Return a JSON list."
            ),
            HumanMessage(
                content="Google was founded in the USA, while Deepmind was founded in the UK"
            ),
        ]
    ]
)

print(output.llm_output)

# Breaking changes to Azure classes
# ... (This section is left unchanged as it's informational and not actual code.)

# Tools
from typing import Literal
from langchain.output_parsers.openai_tools import PydanticToolsParser
from langchain.utils.openai_functions import convert_pydantic_to_openai_tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field

class GetCurrentWeather(BaseModel):
    """Get the current weather in a location."""

    location: str = Field(description="The city and state, e.g. San Francisco, CA")
    unit: Literal["celsius", "fahrenheit"] = Field(
        default="fahrenheit",
        description="The temperature unit, default to fahrenheit",
    )

prompt = ChatPromptTemplate.from_messages(
    [("system", "You are a helpful assistant"), ("user", "{input}")]
)

model = ChatOpenAI(
    model="gpt-3.5-turbo-1106"
).bind(
    tools=[convert_pydantic_to_openai_tool(GetCurrentWeather)]
)

chain = prompt | model | PydanticToolsParser(tools=[GetCurrentWeather])

response = chain.invoke({"input": "what's the weather in NYC, LA, and SF"})
print(response.content)

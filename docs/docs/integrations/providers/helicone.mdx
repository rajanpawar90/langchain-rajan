# Helicone Integration with LangChain

This page covers how to use the Helicone observability platform within LangChain.

## What is Helicone?

Helicone is an open-source observability platform that proxies your OpenAI traffic and provides key insights into your spend, latency, and usage.

![Screenshot of the Helicone dashboard showing average requests per day, response time, tokens per response, total cost, and a graph of requests over time.](/img/HeliconeDashboard.png "Helicone Dashboard")

## Quick Start

To use Helicone in your LangChain environment, follow these steps:

1. Set the `OPENAI_API_BASE` environment variable:

   ```bash
   export OPENAI_API_BASE="https://oai.hconeai.com/v1"
   ```

2. Create an account on [helicone.ai](https://www.helicone.ai/signup) and add your OpenAI API key within the Helicone dashboard to view your logs.

   ![Interface for entering and managing OpenAI API keys in the Helicone dashboard.](/img/HeliconeKeys.png "Helicone API Key Input")

## How to enable Helicone caching

To enable caching, add the `Helicone-Cache-Enabled` header to your requests:




[Helicone caching docs](https://docs.helicone.ai/advanced-usage/caching)

## How to use Helicone custom properties

To use custom properties, add the desired headers to your requests:




[Helicone property docs](https://docs.helicone.ai/advanced-usage/custom-properties)

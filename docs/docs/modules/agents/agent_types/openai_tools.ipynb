{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d9f57826",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 0.1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10aa932",
   "metadata": {},
   "source": [
    "# OpenAI Tools\n",
    "\n",
    "OpenAI models have been fine-tuned to detect when one or more functions should be called and respond with the inputs that should be passed to the function(s). In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call these functions. The goal of the OpenAI tools APIs is to more reliably return valid and useful function calls than what can be done using a generic text completion or chat API.\n",
    "\n",
    "OpenAI terms the capability to invoke a single function as **functions**, and the capability to invoke one or more functions as **tools**. Tools are available in the OpenAI Chat API, which is the recommended option for creating agents using OpenAI models.\n",
    "\n",
    "Using tools allows the model to request that more than one function will be called upon when appropriate. This can help signficantly reduce the time that it takes an agent to achieve its goal.\n",
    "\n",
    "See \n",
    "   \n",
    "* [OpenAI chat create](https://platform.openai.com/docs/api-reference/chat/create) \n",
    "* [OpenAI function calling](https://platform.openai.com/docs/guides/function-calling)\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec89be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b812b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Hub, agent,\n",
    "    OpenAIFunctions, OpenAIToolsAgent, Tool, tools,\n",
    "    TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef71dfc-074b-409a-8451-863feef937ae",
   "metadata": {},
   "source": [
    "## Initialize Tools\n",
    "\n",
    "For this agent, let's give it the ability to search the web with Tavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23fc0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = Tool(
        name='TavilySearchResults',
        func=lambda query: TavilySearchResults(query=query, max_results=1),
        description='Search the web with Tavily'
    )\n",
    "tools = [tavily_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc45217",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e6353c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = Hub.load_prompt(\"hwchase17/openai-tools-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b6bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "# Only certain models support this\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = OpenAIToolsAgent(llm=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146eacb",
   "metadata": {},
   "source": [
    "## Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6d4e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = agent.AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf0c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `TavilySearchResults` with `{'query': 'LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.ibm.com/topics/langchain', 'content': 'LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts  LangChain is an open source orchestration framework for the development of applications using large language models  other LangChain features, like the eponymous chains.  LangChain provides integrations for over 25 different embedding methods, as well as for over 50 different vector storesLangChain is a tool for building applications using large language models (LLMs) like chatbots and virtual agents. It simplifies the process of programming and integration with external data sources and software workflows. It supports Python and Javascript languages and supports various LLM providers, including OpenAI, Google, and IBM.'}]\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is an open source orchestration framework for the development of applications using large language models. It is essentially a library of abstractions for Python and Javascript, representing common steps and concepts. LangChain simplifies the process of programming and integration with external data sources and software workflows. It supports various large language model providers, including OpenAI, Google, and IBM. You can find more information about LangChain on the IBM website: [LangChain - IBM](https://www.ibm.com/topics/langchain)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': 'LangChain is an open source orchestration framework for the development of applications using large language models. It is essentially a library of abstractions for Python and Javascript, representing common steps and concepts. LangChain simplifies the process of programming and integration with external data sources and software workflows. It supports various large language model providers, including OpenAI, Google, and IBM. You can find more information about LangChain on the IBM website: [LangChain - IBM](https://www.ibm.com/topics/langchain)'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"what is LangChain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea6f1b",
   "metadata": {},
   "source": [
    "## Using with chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "178e561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name? Don't use tools to look this up unless you NEED to\",\n",
       " 'chat_history': [{\"role\": \"assistant\", \"content\": \"Hello! How can I help you?\"}, {\"role\": \"user\", \"content\": \"hi! my name is bob\"}],\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\n

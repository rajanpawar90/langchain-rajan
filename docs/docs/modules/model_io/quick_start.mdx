---
sidebar_position: 0
---

# Quickstart

This quick start guide covers the basics of working with language models, including LLMs and ChatModels, PromptTemplates, and Output Parsers.

## Models

We provide several options for using language models:

<Tabs>
  <TabItem value="openai" label="OpenAI" default>

First, install the OpenAI package:




Then, set your API key as an environment variable:




Initialize the models:




  </TabItem>
  <TabItem value="local" label="Local (using Ollama)">

Install Ollama and fetch a model:




Start the Ollama server and initialize the models:




  </TabItem>
  <TabItem value="anthropic" label="Anthropic (chat model only)">

Install the Anthropic package and set your API key as an environment variable:




Initialize the model:




  </TabItem>
  <TabItem value="cohere" label="Cohere">

Install the Cohere package and set your API key as an environment variable:




Initialize the model:




  </TabItem>
</Tabs>

## Prompt Templates

PromptTemplates format inputs to language models. Here's a simple example:




## Output Parsers

OutputParsers convert the raw output of a language model into a usable format. Here's a simple example:




## Composing with LCEL

Combine all these components into a chain:




## Conclusion

This guide covers the basics of working with prompts, models, and output parsers. For more information, see:

- [Prompt documentation](/docs/modules/model_io/prompts/)
- [LLM documentation](/docs/modules/model_io/llms/)
- [ChatModel documentation](/docs/modules/model_io/chat/)
- [Output parser documentation](/docs/modules/model_io/output_parsers/)
